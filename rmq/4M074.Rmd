---
title: 4M074 Probabilités Numériques et Statistique Computationnelle
author: "DU Qiming<p></p> email : duqiming2004@gmail.com"
date: "printemps 2018"
abstract: ""
output:
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true 
    fig_caption: yes
---


```{r cap_ref_functions, include=FALSE}
############################## configuration ############################## 
library(knitr)
## Get the name of this Rmd file
rmdFn <- knitr::current_input()  # filename of input document
## Read lines and close connection
rmdCon <- file(rmdFn, open = 'r')
rmdLines <- readLines(rmdCon)
close(rmdCon)
## Pull out all occurences of at least one back tick, followed 
## by any number of characters, followed by fig$cap (all on one line)
figscap_idx <- grep("`+(.*)fig\\$cap", rmdLines)
rmdLines <- rmdLines[figscap_idx]
## Get rid of everything up until the start of the caption label
## This presumes the caption label is the first argument of fig$cap()
## E.g., fig.cap = fig$cap("my_label", ...)
rmdLinesSansPre <- sub("(.*)fig\\$cap(.*?)[\"']", "", rmdLines)
## Identify everything up until the first quote
match_data <- regexpr("(.*?)[\"']", rmdLinesSansPre)
## Reduce the length by one, because we're not interested in the final quote
attr(match_data, "match.length") <- attr(match_data, "match.length") - 1
## Extract
fig_labels <- regmatches(rmdLinesSansPre, match_data, invert=FALSE)
if (length(fig_labels) > 0) {
    ## Test for duplicates
    if (anyDuplicated(fig_labels) > 0) stop("Duplicate caption labels detected")
}else{
  fig_labels <- c('no_lables')
}

    ## Create a named list of Figure numbers
    ref <- as.list(1:length(fig_labels))
    names(ref) <- fig_labels

## A function for generating captions and cross-references
fig <- local({
  i <- 0
  list(
    cap=function(refName="", text="", col="darkred") {
      i <<- i + 1
      ref[[refName]] <<- i
      css_ctr <- "text-align:center; display:inline-block; width:100%;"
      if(text!="") text <- paste0(": ", text)
      cap_txt <- paste0("<span style=\"color:", col, "; ", css_ctr, "\">Figure ", i, text , "</span>")
      return(paste0(refName,'&',cap_txt))

    },
    
    ref=function(refName, checkRef=TRUE) {
    if (checkRef && !refName %in% names(ref)) stop(paste0("fig$ref() error: ", refName, " not found"))
        paste0("<A HREF=\"#fig", refName, "\">Figure ", ref[[refName]], "</A>")})})
## Replace default hook for processing plots & add figure anchor
knit_hooks$set(plot = function(x, options,
                             fig_scale_factor = "80%") {
  sty <- paste0(" style=\"text-align:center", ";\"")
  info = strsplit(options$fig.cap,'&')[[1]]
  refName = info[1]
  cap_txt = info[2]
  figanchor <- paste0("<a name=\"fig", refName, "\"></a>")
  paste('<figure', sty, '>', figanchor, '<img src="',
    opts_knit$get('base.url'), paste(x, collapse = '.'),
    '" width = ',fig_scale_factor, '><figcaption>', cap_txt, '</figcaption></figure>','<p></p>',
    sep = '')
})

############################## configuration ############################## 
```

Je donne une liste des problèmes posés par les étudiants pendant le TP (groupe 2 de 4M074 2018).
Comme il s'agit beaucoup de détails pour faire des codes **jolis**, je trouve que
c'est plus raisonable d'apprendre les détails petit à petit. Je sélectionne les problèmes qui
sont (sans doute) intéressants pour qu'on peut avancer ensemble.  

N'hésitez pas de m'envoyez un [email](mailto:duqiming2004@gmail.com) pour 
poser des questions ou corriger mon français.


**misc:**

 * [cette page](https://github.com/mgimm/TP) 
 * [Un Rmd template](https://github.com/mgimm/Rmd-template/)  
 * [Un livre très très bon pour les débutants d'info (surtout nous : les étudiants de maths)](https://info201.github.io/index.html)
 * [TP noté I
   (ancien)](https://mgimm.github.io/blog/public/pdf/TP_not%C3%A9_I(Gr.2)_corrig%C3%A9.zip)
   
# TP4(corrigé) et TP5(sujet) 20-02-2018

 * [TP4 corrigé](https://mgimm.github.io/TP/doc/TP4_corrige.zip)
 * [TP5 sujet](https://mgimm.github.io/TP/doc/TP5_sujet.zip)




# Environnements de ```R``` 

On travaille principalement sur 
[Jupyter Notebook](https://jupyter.readthedocs.io/en/latest/index.html) 
avec 
[IRkernel](https://irkernel.github.io/). Vous pouvez
aussi utiliser [Rstudio](https://www.rstudio.com/).
Voici un guide pour l&#39;installation de Jupyter et
IRkernel pour tous les OS.

[Installation 
de Python et
Jupyter](https://mgimm.github.io/blog/misc/2016/11/17/Installation-python/)

Si vous avez des problèmes sur la configuration, n&#39;hésitez pas de me
parler. De plus, [sagecloud](https://cloud.sagemath.com/settings) nous permet de
compiler les notebooks en ligne (graduit). 

## Conseils pour les débudants de `R`

Si vous n&#39;avez jamais suivi un cours de `R`, vous trouvrez dans les
liens suivants deux documents par madame Tabea Rebafka pour le cours 4M015.

* [Prise en main de
  R](https://mgimm.github.io/blog/public/pdf/Prise_en_main_de_R.pdf) 
* [Programmation en
  R](https://mgimm.github.io/blog/public/pdf/Programmation_en_R.pdf)

# Rappels 

## Matrices des figures

Cas simple :

```{r, fig.height=3, fig.cap=fig$cap("hist1", "Matrice d'histogrammes"), echo = TRUE}
par(mfrow=c(1,3))
hist(rnorm(500), breaks=30)
hist(rexp(500), breaks=30)
hist(runif(500), breaks=30)
```
Cas (un peu) compliqué:

```{r,  fig.cap=fig$cap("hist2", "Matrice d'histogrammes"), echo = TRUE}
# One figure in row 1 and two figures in row 2
layout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE))
hist(rnorm(500), breaks=30)
hist(rexp(500), breaks=30)
hist(runif(500), breaks=30)
```

## `lines` et `curve`

```{r,  fig.cap=fig$cap("lines", "ex. de la fonction _lines_"), echo = TRUE}
hist(rexp(300), freq=FALSE, breaks = 40)
x<-seq(0,8,by=.1)
# ici, x est un vecteur
lines(x, dexp(x), col = 'darkred')
```

```{r,  fig.cap=fig$cap("curve", "ex. de la fonction _curve_"), echo = TRUE}
hist(rexp(300), freq=FALSE, breaks = 40)
# ici, x est qqch abstrait
# pour aller plus loin  ?expression
curve(dexp(x), col = 'darkred', add=TRUE, from=.001)
```

# Remarques du TP

## TP1

### un exemple de `optimize`

On remarque que cette fonction n'est pas (du tout) magique 
pour l'optimisation non-convexe. Mais dans le cas convexe,
il marche très bien.
 
```{r}
f<-function(x){return(x^2+sin(5*x))}
opt<-optimize(f, interval=c(-3,3), maximum=F, tol=0.01)
x_min<-opt$objective
```

```{r,  fig.cap=fig$cap("optimize", "ex. de la fonction _optimize_"), echo = TRUE}
curve(f(x), from=-3, to=3)
points(x_min, f(x_min), col='darkred',pch=19)
grid()
```
### un exemple de `findInterval`

rappel de la définition de l'inverse généralisée d'une fonction réelle $F$,
 noté $F^{-1}$

$$
F^{-1}(x) = \inf\{y\in \mathbb{R}: F(y)\geq x\}
$$
```{r}
x_inv<-findInterval(0.6, cumsum(dbinom(0:10,10,0.2)))
```
```{r,  fig.cap=fig$cap("etage", "ex. de la fonction _findInterval_"), echo = TRUE}
plot(0:10,cumsum(dbinom(0:10,10,0.2)))
points(x_inv,cumsum(dbinom(0:10,10,0.2))[x_inv+1] , col='darkred',pch=19)
grid()
```

## TP2 

### Copule Gaussienne

On commence par un cas particulier ($dim = 2$). La copule est un objet
pour décrire la dépendance entre les v.a. Pour les v.a. gaussienne, la
dépendance est totallement définie par la matrice de covariance.

Soit $(X_1,X_2) \sim \mathcal{N}_2 (0, \Gamma_2)$, où la matrice de
covariance est de forme. 

$$\Gamma_2 = \begin{pmatrix}
1   &   \rho \\
\rho  &    1
\end{pmatrix}$$

Par la construction, on a bien que les lois marginales

$$\mathcal{L}(X_1) =
\mathcal{L}(X_2) = \mathcal{N}(0,1)$$

Alors, comme la f.d.r. $\Phi\in \mathscr{C}^0$ 

$$(U_1,U_2) = (\Phi(X_1),\Phi(X_2))$$

est bien la copule qu&#39;on cherche à simuler.

On reviens au cas où $dim = n$. Si on simule $(Z_1,\dots,Z_n)$ par

$$\forall i \in \{1,2,\dots,n\}\qquad Z_i = \sqrt{\rho} G_0 + \sqrt{1-\rho} G_i$$

où $G_i$ sont les normals standards indépandantes, c&#39;est facil à vérifier
que

$$\mathrm{Var}[Z_i] = 1\qquad et \qquad 
\mathrm{Cov}[Z_i Z_j] = \rho \qquad \forall i\neq j\in\{1,2,\dots,n\}$$

Alors, la matrice de covariance associée est de la forme 

$$ \Gamma_n = \begin{pmatrix}
  1 & \rho & \cdots & \rho \\
  \rho & 1 & \cdots & \rho \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  \rho & \rho & \cdots & 1 
 \end{pmatrix}
$$

Donc, pour simuler $(U_1,U_2,\dots,U_n)$ la copule gaussienne associée, il faut juste prendre

$$U_i = \Phi(Z_i) \qquad \forall i \in \{1,2,\dots,n\}$$

L'intérêt de cette méthode est que si vous voulez simuler les vecteurs
gaussiens avec $\Gamma$ différents, on peut simuler $(G_i)_{0\leq i \leq N}$ une seule fois
et ceux qui restent sont des calculs numériques. Il nous permet aussi de faire la
simulation 'dépendante' parallèlement.

### Urne d&#39;Ehrenfest

On remarque que la loi invariante est bien $\mathcal{B}(d,\frac12)$.

$$\forall k \in [0:d], \qquad \mathbf{P}(X_n = k) =
\frac{1}{2^d}\binom{d}{k}$$

#### Pourquoi ?

Une manière intuitive de regarder ce problème est de tracer une boule.
Imaginons que l'on a déjà fait une infinité de fois de transitions. 
Alors, une certaine boule soit dans A ou dans B est indépendant que les autres
boules,
qui suits bien une loi Bernoulli avec proba $\frac12$.
Donc, le cardinal de l'urne A suits bien une loi
binomiale. 

Or, c'est facile à vérifier que cette chaine est irréductible et récurrente
positive (dim. finie). Elle admet une unique loi invariante. Alors il suffit de vérifier
que 

$$X_0 \sim \mathcal{B}(d,\frac12)\implies X_1 \sim \mathcal{B}(d,\frac12)$$


#### Chaine d&#39;Ehrenfest modifiée

On modifie un peu la modélisation précédente en considérant la règle
suivante: "_on tire un numéro de balle selon la loi uniforme sur
$\{1,2,\dots,d\}$ et à un tirage $i$ on déplace la balle numéro $i$ d'une
urne à l'autre __avec probabilité 1/2___".

Intuitivement, on a la chaine modifiée est une chaine apériodique
irréductible d'états finis, il y a donc une convergence à la vitesse
géométrique vers la loi invariante $\pi$. On note $\mu_0$ la loi initial et
$M'$ la trasition modifiée 

$$\forall f \in \mathcal{B}_b([0:d]),\qquad |\mu_0 (M')^n (f)  - \pi (f)|\leq
C\alpha^n \Vert f\Vert_{\infty}$$ 

avec $C>0$ une const. et $0<\alpha<1$. 

On remarque que la chaine origine est périodique avec période = 2, il n'y a donc pas de
convergence vers la loi invariante.

On note $M$ le noyau de transition pour la chaine origine et $\pi_0$
la loi invariante associée. on a 

$$M'(x, dy) = \frac12 M(x,dy) + \frac12\delta_x(dy)$$

Alors, c'est facil à vérifier que

$$\pi_0 M' = \frac12\pi_0 M + \frac12\pi_0 = \pi_0$$

Par l'unicité de la loi invariante, on a $\pi = \pi_0$.


### Processus de Poisson inhomogène

Soit $\lambda:[0,+\infty[ \to ]0, +\infty[$
une fonction strictement positive, appelée fonction d'intensité.
On considère maintenant des instants de sauts $(T_n)_{n \geq 1}$

(avec toujours $T_0 = 0$) donnés par la dynamique $T_{n} = T_{n-1} + S_n$ 
où pour tout $n \geq 1$, $S_n$ est une variable aléatoire sur 
$]0,+\infty[$ définie conditionnellement à $T_{n-1}$ par 

$$
    \begin{aligned}
    \forall s > 0, \forall t_{n-1} > 0, \quad
    \mathbf{P} \bigl[S_n > s \; \bigl\vert \; T_{n-1} = t_{n-1} \bigr] &= \exp \bigl(-\int_0^s \lambda(u + t_{n-1}) d u \bigr) \\
      &= \exp \bigl(- (\Lambda(t_{n-1} + s) - \Lambda(t_{n-1})) \bigr) \\
    \end{aligned}
$$

avec $\Lambda(t) = \int_0^t \lambda(u) d u$ l'intensité intégrée. Dans la suite on note $\Lambda^{-1}$ la réciproque de $\Lambda$.

#### Simulation par inverse de l&#39;intensité intégrée

Montrer que si $E \sim \mathcal{E}(1)$ et que $t_{n-1}$ est fixé, alors la variable aléatoire $X = \Lambda^{-1}\bigl(E + \Lambda(t_{n-1})\bigr) - t_{n-1}$ vérifie 

$$ 
    \forall s > 0, \quad 
    \mathbf{P} \bigl[X > s \bigr] = \exp \bigl(- (\Lambda(t_{n-1} + s) - \Lambda(t_{n-1})) \bigr),
$$

_preuve_ :

Puisque $\lambda$ est une fonciton strictement positive, l'application $\Lambda : t \rightarrow \Lambda(t)$ est strictement croissante sur $\mathbb{R}_+$. 

Alors, on a

$$ 
\begin{aligned}
\mathbf{P}\big[ X > s\big] &= \mathbf{P}\big[\Lambda^{-1}\big(E + \Lambda(t_{n-1})\big) - t_{n-1} > s \big]\\
&=\mathbf{P}\big[E + \Lambda(t_{n-1}) > \Lambda(t_{n-1}+s)\big]\\
&=\mathbf{P}\big[E > \Lambda(t_{n-1}+s)-\Lambda(t_{n-1}) \big]\\
&=\exp \bigl(- (\Lambda(t_{n-1} + s) - \Lambda(t_{n-1})) \bigr)
\end{aligned}
$$ 

C'est-à-dire, on a

$$\mathcal{L}\big(X \; \big\vert \; T_{n-1} = t_{n-1}\big) = \mathcal{L}\big(S_n \; \big\vert \; T_{n-1} = t_{n-1}\big)$$

<span style="float: right">&#9633;</span>
<br>
en déduire une méthode de simulation des instants de sauts $(T_n)_{n \geq 1}$ et du processus de comptage associé (appelé processus de Poisson inhomogène de fonction d'intensité $\lambda$).



Tester cette méthode avec la fonction d'intensité $\lambda(t) = 0.1 + 5t$.

```{r, fig.cap=fig$cap("poisson1", "Processus de Poisson inhomogène")}

lambda <- function(t) return(0.1 + 5*t)
Lambda <- function(t) return(0.1*t + 2.5*t^2 )
Lambda_inv <- function(s) return(-0.02 + 0.2*sqrt(0.01+10*s))

X_cond <- function(t) {
    E <- rexp(1);
    X <- Lambda_inv (E + Lambda(t)) - t;
    return(X);
}


# svglite("poisson_inhomogene.svg")
Npaths <- 200
T <- 4
plot(NULL, xlim=c(0,T), ylim=c(0,25), xlab="Time t", ylab="Processus de comptage N_t",
     main = paste(Npaths, "trajectoires d'un processus de Poisson inhomogène"))

# on fait simple et on illustre ici l'utilisation d'une boucle for et d'une boucle while
for (k in 1:Npaths) {
    T_n <- 0
    path <- 0
    while (T_n < T) {
        T_n <- T_n + X_cond(T_n) 
        if (T_n < T) path <- c(path, T_n)
    }
    N_T <- length(path)-1
    N <- 0:N_T

    # on ajoute pour faire joli le dernier point (T, N_T)    
    path <- c(path, T)
    N <- c(N, N_T)
    
    lines(path, N, type="s", col=rgb(0,0,1,alpha=0.5))
}
grid()

``` 


#### Simulation par la méthode des sauts fictifs (thinning)

On suppose maintenant que la fonction d'intensité est bornée 

$$
    \exists \bar \lambda > 0, \quad \forall t \ge 0, \quad \lambda(t) \le \bar \lambda.
$$

Soit $(\bar T_n)_{n \geq 1}$

 les instants de sauts d'un processus de poisson 
$(\bar N_t) (t \geq 0)$ d'intensité $\bar \lambda$.
On peut simuler les instants de sauts $(T_n) (n \ge 1)$ en supprimant certains sauts de 
$(\bar T_n) (n \ge 1)$. Plus précisément, on considère $(U_n)(n \ge 1)$ une suite _i.i.d._ de loi uniforme sur $[0,1]$ et on construit la suite d'indices $(\tau_n)(n \ge 1)$ par la récurrence

$$
     \forall n \ge 0, \quad \tau_{n+1} = 
     \min \Bigl\{ k > \tau_n, U_k \le \frac{\lambda(\bar T_k)}{\bar \lambda} \Bigr\}
     \qquad \tau_0 = 0
$$

Alors les sauts de $(\bar N_t)(t \ge 0)$ d'indices $(\tau_n)(n \ge 1)$ sont les sauts d'un processus de Poisson inhomogène de fonction d'intensité $\lambda$. On peut alors construire $(T_n)(n \ge 1)$ en posant $T_n = \bar T_{\tau_n}$.

```{r, eval=FALSE, echo=TRUE}
tau_update <- function(tau,lambda_bar, T_bar){
    
    # tau: tau_n
    # lambda_bar: la borne de l'indensité
    # T_bar: un vecteur des instants de sauts d'un processus de Poisson
    
    k <- tau
    while(runif(1) > T_bar[k]/lambda_bar){
        k <- k+1
    }
    # la sortie: tau_{n+1}
    return(k)
}
```

#### Variable de contrôle

Soit $X$ une v.a. et on s'intéresse à estimer sa moyenne $\mathbf{E}[X]$ par la méthode de monte-carlo.
Soit $Y$ une v.a. telle que l'on sait la moyenne $\mathbf{E}[Y]$.
Alors, on a 

$$\mathbf{E}[X] = \mathbf{E}[X-\alpha Y] + \alpha \mathbf{E}[Y]$$

On suppose que on sait simuler suivant la loi $\mathcal{L}(X)$. Alors,
on s'intéresse au cas où 

$$\mathrm{Var}[X - \alpha Y] \leq \mathrm{Var}[X]$$

C'est facil à vérifier que une condition nécéssaire est que 

$$\mathrm{Cov}[X,Y] \neq 0$$

Et si $\alpha \in (0,\frac{-2\mathrm{Cov}[X,Y]}{\mathrm{Var}[Y]})$ (ou $\alpha \in (\frac{-2\mathrm{Cov}[X,Y]}{\mathrm{Var}[Y]},0)$),
on a $\mathrm{Var}[X - \alpha Y] \leq \mathrm{Var}[X]$. 

De plus, $\mathrm{Var}[X - \alpha Y]$ atteint son minimum lorsque $\alpha = -\frac{\mathrm{Cov}(X,Y)}{\mathrm{Var}[Y]}$. 
